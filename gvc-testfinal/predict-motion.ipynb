{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepsetmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     Sequential \u001b[38;5;28;01mas\u001b[39;00m Seq,\n\u001b[1;32m     16\u001b[0m     Linear \u001b[38;5;28;01mas\u001b[39;00m Lin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     Conv1d,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepsetmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     28\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepsetmodel'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Set, Dict, Tuple\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (\n",
    "    Sequential as Seq,\n",
    "    Linear as Lin,\n",
    "    ReLU,\n",
    "    BatchNorm1d,\n",
    "    AvgPool1d,\n",
    "    Sigmoid,\n",
    "    Conv1d,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "from deepsetmodel import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "import random \n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Here i load a paired datatset.\n",
    "\n",
    "Unlike the other (unpaird) datatset which contains individual briefs. \n",
    "\n",
    "Each row of the paired datast contains two set of briefs. Where each set corresponds to either oppostion and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRED_PATH = '../dataset/paired_testset.csv' #'../summaries/summarized_paired_testset.csv'\n",
    "\n",
    "testset = pd.read_csv('../dataset/paired_testset.csv', sep=',',index_col=0)\n",
    "\n",
    "testset = testset.loc[testset['data_type'] == 'train']\n",
    "\n",
    "# randomly set 20% of the data to test Validation set\n",
    "testset['data_type'] = testset['data_type'].apply(lambda x: \"test\" if random.random() < 0.2 else \"train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader *\n",
    "\n",
    "Just like the LLM Notebook you will have to run the cells below multiple times to run different experiments.\n",
    "\n",
    "As of the time this note was written,  If you want to specify the input type (\"tfidf\" or \"embedding\"), then set feature variable below.\n",
    "\n",
    "The Data class returns a pytorch dataset object.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data class definition\n",
    "\n",
    "Below is the signature of the Data class:\n",
    "\n",
    "<font color=\"blue\">def __init__(self,df,feature = 'tfidf', getEmbeddings = sentence_model.encode ,support_pipe = '../pipes/support-tfidf.joblib', opposition_pipe = '../pipes/oppose-tfidf.joblib', both =False, both_pipe = '../pipes/both-tfidf.joblib')</font>\n",
    "\n",
    "`self.feature`: This specifies the feature engineering technique to use on the dataset. \n",
    "                There are only 2 feature types implemented: [\"tfidf\", \"embeddings\"]\n",
    "\n",
    "\n",
    "`self.getEmbeddings`: This refers to the embedding function that will be used on the text. You can pick use your own embedding function. You don't have to specify an embedding function the default is already specified for you. \n",
    "\n",
    "`self.both`: When set to True a dataset where the supporting and opposing briefs are joined (Unioned) together to from one set of briefs.\n",
    "             When Set to False a dataset of disjointed supporting and oppossing breifs are joined. \n",
    "             You have to make sure that if you set this to true, then you have to set the configuration for the model to accept datasets that are joined.\n",
    "\n",
    "`self.support_pipe, self.opposition_pipe`: These are paths to pipes that convert text to tfidf vectors. Default paths are provided, so you don't have to explicitly set it.\n",
    "\n",
    "`self.both_pipe`: This is a path that converst text to tfidf vectors. This requires particular attention, because this pipe is constructed from both support and opposition. It is does a requirement is you set `self.both` to True. Default paths are provided, so you don't have to explicitly set it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples and Usecase:\n",
    "\n",
    "Example 1.\n",
    "<font color=\"blue\">train_data = Data(testset[testset['data_type'] == 'train'], feature='embedding' ,both=True)</font>:\n",
    "\n",
    "returns an embedding dataset where support and oppositions are combined.\n",
    "\n",
    "Example 2.\n",
    "<font color=\"blue\"> train_data = Data(testset[testset['data_type'] == 'test'], feature='tfidf' ,both=False) </font>:\n",
    "\n",
    "returns a tfidf dataset where where support and opposiontions are seperated.\n",
    "\n",
    "Example 3.\n",
    "```\n",
    "def embedding_func(brief):\n",
    "    \n",
    "    ....\n",
    "```\n",
    "<font color=\"blue\"> train_data = Data(testset[testset['data_type'] == 'test'], feature='embedding',both=False , getEmbeddings = embedding_func ): </font>\n",
    "\n",
    "returns a embedding dataset where the embedding function is explicitly defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratchB/oqcardoso/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.3.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/scratchB/oqcardoso/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.3.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/scratchB/oqcardoso/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.3.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self,df,feature = 'tfidf', getEmbeddings = sentence_model.encode ,support_pipe = '../pipes/support-tfidf.joblib', opposition_pipe = '../pipes/oppose-tfidf.joblib', both =False, both_pipe = '../pipes/both-tfidf.joblib'):\n",
    "        self.df = df    \n",
    "        supports = self.df['support'].values\n",
    "        oppositions = self.df['opposition'].values\n",
    "        self.folder_id = self.df['folder_id'].values\n",
    "        self.y = self.df['outcome'].values \n",
    "        # convert list of stings to list of lists of stings\n",
    "        supports = list(map(lambda x: ast.literal_eval(x), supports))\n",
    "        oppositions = list(map(lambda x: ast.literal_eval(x), oppositions))\n",
    "        self.both = both\n",
    "        if self.both:\n",
    "            self.combined = list(map(lambda x,y: x+y, supports,oppositions))\n",
    "\n",
    "\n",
    "        self.getEmbeddings = getEmbeddings\n",
    "        \n",
    "        if self.both == False:\n",
    "            self.max_len_brief = max(self.findMaxLen(supports),self.findMaxLen(oppositions))\n",
    "        else:\n",
    "            self.max_len_brief = self.findMaxLen(self.combined)\n",
    "\n",
    "        if feature == 'tfidf':\n",
    "            if self.both == False:\n",
    "                support_pipe = load(support_pipe)\n",
    "                opposition_pipe = load(opposition_pipe)\n",
    "                getSupport = lambda x: self.stringsToTfidfs(x,support_pipe)\n",
    "                getOpposition = lambda x: self.stringsToTfidfs(x,opposition_pipe)\n",
    "\n",
    "\n",
    "                self.supports = list(map( getSupport, supports))\n",
    "                self.oppositions = list(map( getOpposition, oppositions))\n",
    "\n",
    "            else:\n",
    "                both_pipe = load(both_pipe)\n",
    "                getTfidf= lambda x: self.stringsToTfidfs(x,both_pipe)\n",
    "                self.combined = list(map( getTfidf, self.combined))\n",
    "\n",
    "        elif feature == 'embedding':\n",
    "            if self.both == False:\n",
    "                self.supports: list = list(map(lambda x: self.stringsToEmbeddings(x), supports))\n",
    "                self.oppositions: list = list(map(lambda x: self.stringsToEmbeddings(x), oppositions))\n",
    "            else:\n",
    "                self.combined: list = list(map(lambda x: self.stringsToEmbeddings(x), self.combined))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.both == False:\n",
    "            return len(self.supports)\n",
    "        else:\n",
    "            return len(self.combined)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = 1.0 if self.y[idx] == 'grant' else 0.0\n",
    "\n",
    "        if hasattr(self, 'combined') and self.both == True:\n",
    "            return self.combined[idx] , y , self.folder_id[idx]\n",
    "        else:\n",
    "            return self.supports[idx] , self.oppositions[idx] , y , self.folder_id[idx]\n",
    "        \n",
    "    def findMaxLen(self,x):\n",
    "        max_len = 0\n",
    "        for i in range(len(x)):\n",
    "            row = x[i]\n",
    "            if len(row) > max_len:\n",
    "                max_len = len(row)\n",
    "        return max_len\n",
    "\n",
    "    def stringsToTfidfs(self,briefs: List[str],pipe):\n",
    "        tfidfs = torch.tensor(pipe.transform(briefs).toarray(),dtype=torch.float32)\n",
    "\n",
    "        return self.padFeatures(tfidfs)\n",
    "    \n",
    "\n",
    "    \n",
    "    def stringsToEmbeddings(self,briefs: List[str]):\n",
    "        embeddings =  torch.tensor(self.getEmbeddings(briefs),dtype=torch.float32)\n",
    "        return self.padFeatures(embeddings)\n",
    "    \n",
    "    def padFeatures(self,features: List[torch.tensor]):\n",
    "        num_padding = self.max_len_brief - features.shape[0]\n",
    "        padding = nn.ConstantPad2d((0, 0, 0, num_padding), 0)\n",
    "        features = padding(features)\n",
    "        features = features.T\n",
    "        return features\n",
    "    \n",
    "\n",
    "feature = 'tfidf'\n",
    "\n",
    "train_data = Data(testset[testset['data_type'] == 'train'], feature=feature ,both=True)\n",
    "test_data = Data(testset[testset['data_type'] == 'test'], feature=feature ,both=True)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# warning about pickle version *Vectorizer from version 1.3.2 when using version 1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation *\n",
    "\n",
    "In the cell below is where the size of the model is defined.\n",
    "Here you have to ability to increase or decreace the number of hidden units per layer.\n",
    "\n",
    "Just like the Dataloader tab above you have to run this cell once per experiment.\n",
    "\n",
    "You can only select one out of three types of models [\"support\", \"opposition\",\"both\"]\n",
    "\n",
    "specify your choice in the variable key\n",
    "\n",
    "Example\n",
    "``` key = \"both\" ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Notes to myself:\n",
    "\n",
    "The performance of the DeepSet model maybe hampered because of the small latent space.\n",
    "The machie i am using cannot handle a larger latent space. Once you get a larger GPU memory retry this scipt with a larger latent space\n",
    "\n",
    "\n",
    "\n",
    "Ideas on reducing the load on GPUs:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html\n",
    "\n",
    "When you have time learn this:\n",
    "\n",
    "https://docs.wandb.ai/guides/model_registry/walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TFIDF is quiet big so i may have to reduce the hiden layers width\n",
    "# the latent space has the be atleast the size of the input\n",
    "\n",
    "models = {}\n",
    "optimizers = {}\n",
    "\n",
    "key = \"both\"\n",
    "\n",
    "if key == \"support\":\n",
    "    input_size = train_data.supports[0].shape[0]\n",
    "elif key == \"opposition\":\n",
    "    input_size = train_data.oppositions[0].shape[0]\n",
    "else:\n",
    "    input_size = train_data.combined[0].shape[0]\n",
    "\n",
    "\n",
    "max_len_brief = train_data.max_len_brief\n",
    "\n",
    "hidden1 = int(input_size /5)\n",
    "hidden2 = int(hidden1 / 4)\n",
    "hidden3 = int(hidden2 / 3)\n",
    "classify1 = int(hidden3 /2)\n",
    "\n",
    "models[key] = DeepSets(input_size, max_len_brief , hidden1, hidden2, hidden3, classify1).to(device)\n",
    "\n",
    "latent_size = int(input_size / 10)\n",
    "hidden_size = latent_size\n",
    "output_size =  1\n",
    "\n",
    "\n",
    "\n",
    "## what does Bachnorm and conv1d work?\n",
    "lr = 1e-4   \n",
    "optimizers[key] = torch.optim.Adam(models[key].parameters(), lr=lr)\n",
    "#optimizers[\"opposition\"] = torch.optim.Adam(models[\"opposition\"].parameters(), lr=1e-4)\n",
    "#optimizers[\"both\"] = torch.optim.Adam(models[\"both\"].parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "These are functions for  training, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, total, batch_size, leave=False , datatype='support', loss_fn= nn.BCELoss()):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "\n",
    "    t = tqdm(enumerate(loader), total=total /batch_size, leave=leave)\n",
    "\n",
    "    csv = {'folder':[],'prediction':[], 'score':[], 'truth':[]}\n",
    "\n",
    "    for i, data in t:\n",
    "\n",
    "        if datatype != \"both\":\n",
    "            supports, oppositions, y , folder_id = data\n",
    "            supports = supports.to(device)\n",
    "            oppositions = oppositions.to(device)\n",
    "        else:\n",
    "            combined, y , folder_id = data\n",
    "            combined = combined.to(device)\n",
    "\n",
    "        y = y.float()\n",
    "        y = y.reshape(-1,1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if datatype == 'support':\n",
    "            outputs= model(supports)\n",
    "        elif datatype == 'opposition':\n",
    "            outputs= model(oppositions)\n",
    "        elif datatype == 'both':\n",
    "            outputs= model(combined)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "        predictions = (outputs > 0.5)\n",
    "        acc = (predictions == y).sum().item()\n",
    "        sum_acc += acc\n",
    "        avg_acc =  acc /batch_size\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        t.set_description(f\"batch_loss_{datatype}: {loss.item():.4f} \\t| sum_loss_{datatype}: {sum_loss:.4f}\\n batch_accuracy_{datatype}: {avg_acc:.4f}\")\n",
    "        \n",
    "        t.refresh()\n",
    "\n",
    "        csv['folder'].extend(folder_id)\n",
    "        csv['prediction'].extend(predictions.cpu().numpy().flatten())\n",
    "        csv['score'].extend(outputs.cpu().numpy().flatten())\n",
    "        csv['truth'].extend(y.cpu().numpy().flatten())\n",
    "\n",
    "        \n",
    "    # what is the (i+1) for?\n",
    "        \n",
    "    return sum_loss  / len(loader.dataset) , sum_acc / len(loader.dataset) , pd.DataFrame(csv)\n",
    "\n",
    "\n",
    "def train(model, optimizer, loader, total, batch_size, leave=False, datatype='support', loss_fn= nn.BCELoss()):\n",
    "    model.train()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    t = tqdm(enumerate(loader), total=total /batch_size, leave=leave)\n",
    "    for i, data in t:\n",
    "\n",
    "        if key != \"both\":\n",
    "                \n",
    "            supports, oppositions, y , _ = data\n",
    "            supports = supports.to(device)\n",
    "            oppositions = oppositions.to(device)\n",
    "\n",
    "        else:\n",
    "            combined, y , _ = data\n",
    "            combined = combined.to(device)\n",
    "\n",
    "        y = y.float()\n",
    "        y = y.reshape(-1,1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if datatype == 'support':\n",
    "            outputs= model(supports)\n",
    "        elif datatype == 'opposition':\n",
    "            outputs= model(oppositions)\n",
    "        elif datatype == 'both':\n",
    "            outputs= model(combined)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        #wandb.log({\"batch_loss\": loss.item() } )\n",
    "      \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        t.set_description(f\"batch_loss_{datatype}: {loss.item():.4f} \\t| sum_loss_{datatype}: {sum_loss:.4f}\")\n",
    "        t.refresh()\n",
    "\n",
    "    return sum_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "The cell below is where the model is trained , tested, used for inference and saved to disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a573ef8fb8a54dca91d31d8d53d430a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moqcardoso\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6491855cc778437c905ceb7344fb7c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113083279795117, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratchB/oqcardoso/motion_prediction/per_motion_prediction/wandb/run-20240318_181052-w61fkvc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oqcardoso/DeepSets/runs/w61fkvc8' target=\"_blank\">boths-val-tfidf-epochs:300-patience:100 epochs</a></strong> to <a href='https://wandb.ai/oqcardoso/DeepSets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oqcardoso/DeepSets' target=\"_blank\">https://wandb.ai/oqcardoso/DeepSets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oqcardoso/DeepSets/runs/w61fkvc8' target=\"_blank\">https://wandb.ai/oqcardoso/DeepSets/runs/w61fkvc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f187ad925b432ea9ac4b051f8df2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52.25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.15 GiB. GPU 1 has a total capacity of 23.64 GiB of which 3.92 GiB is free. Process 21292 has 922.00 MiB memory in use. Including non-PyTorch memory, this process has 18.83 GiB memory in use. Of the allocated memory 17.62 GiB is allocated by PyTorch, and 95.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     12\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# set the wandb project where this run will be logged\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSets\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     }\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m---> 47\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     valid_loss, valid_acc , csv \u001b[38;5;241m=\u001b[39m test(\n\u001b[1;32m     59\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodels[key],\n\u001b[1;32m     60\u001b[0m         loader\u001b[38;5;241m=\u001b[39mtest_loader, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         datatype\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     67\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: avg_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: valid_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: valid_acc})\n",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader, total, batch_size, leave, datatype, loss_fn)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#wandb.log({\"batch_loss\": loss.item() } )\u001b[39;00m\n\u001b[1;32m     93\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 95\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m t\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_loss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatatype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m| sum_loss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatatype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m t\u001b[38;5;241m.\u001b[39mrefresh()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/optim/adam.py:579\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    577\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    582\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 1 has a total capacity of 23.64 GiB of which 3.92 GiB is free. Process 21292 has 922.00 MiB memory in use. Including non-PyTorch memory, this process has 18.83 GiB memory in use. Of the allocated memory 17.62 GiB is allocated by PyTorch, and 95.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "n_epochs = 300\n",
    "stale_epochs = 0\n",
    "best_valid_acc = 0.0\n",
    "patience = 100\n",
    "t = tqdm(range(0, n_epochs))\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DeepSets\",  \n",
    "    name= f\"{key}s-val-{feature}-epochs:{n_epochs}-patience:{patience} epochs\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \n",
    "    \"lr\": lr,\n",
    "\n",
    "    \"dataset\": f\"single-{key}\",\n",
    "\n",
    "    \"epochs\": n_epochs,\n",
    "\n",
    "    \"patience\": patience,\n",
    "\n",
    "    \"architecture\":\"ConvolutionalDeepSets\",\n",
    "\n",
    "\n",
    "    \"hidden1\" : hidden1,\n",
    "\n",
    "    \"hidden2\" : hidden2,\n",
    "\n",
    "    \"hidden3\" : hidden3,\n",
    "\n",
    "    \"classify1\" : classify1,\n",
    "\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in t:\n",
    "    avg_loss = train(\n",
    "        model=models[key], \n",
    "        optimizer=optimizers[key], \n",
    "        loader=train_loader, \n",
    "        total=len(train_data), \n",
    "        batch_size=batch_size, \n",
    "        leave=bool(epoch == n_epochs - 1),\n",
    "        datatype=key \n",
    "    )\n",
    "    \n",
    "    \n",
    "    valid_loss, valid_acc , csv = test(\n",
    "        model=models[key],\n",
    "        loader=test_loader, \n",
    "        total=len(test_data), \n",
    "        batch_size=batch_size, \n",
    "        leave=bool(epoch == n_epochs - 1),\n",
    "        datatype=key\n",
    "    )\n",
    "    \n",
    "    wandb.log({\"train_loss\": avg_loss, \"valid_loss\": valid_loss, \"valid_acc\": valid_acc})\n",
    "\n",
    "    print(\"Epoch: {:02d}, Training Loss:   {:.4f}\".format(epoch, avg_loss))\n",
    "    print(\"           Validation Loss: {:.4f}\".format(valid_loss))\n",
    "    print(\"           Validation Accuracy: {:.4f}\".format(valid_acc))\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        modpath = osp.join(f\"../models/DeepSets_{key}_{feature}.pth\")\n",
    "        print(\"New best model saved to:\", modpath)\n",
    "        torch.save(models[key].state_dict(), modpath)\n",
    "        # save csv\n",
    "        csv[\"folder\"] = csv[\"folder\"].astype(int)\n",
    "        csv[\"prediction\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"prediction\"]]\n",
    "        csv[\"truth\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"truth\"]]\n",
    "        \n",
    "        csv.to_csv(f\"../predictions/DeepSets_{key}_{feature}_predictions.csv\", index=False)\n",
    "\n",
    "        stale_epochs = 0\n",
    "    else:\n",
    "        print(\"Stale epoch\")\n",
    "        stale_epochs += 1\n",
    "    if stale_epochs >= patience:\n",
    "        print(\"Early stopping after %i stale epochs\" % patience)\n",
    "        break\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"folder_id\"] = csv[\"folder_id\"].astype(int)\n",
    "csv[\"prediction\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"prediction\"]]\n",
    "csv[\"truth\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"truth\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

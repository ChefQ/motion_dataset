{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note \n",
    "You will have to run this notebook six times:\n",
    "1. Support with Tfidf\n",
    "2. Support with Embeddings\n",
    "3. Opposition with Tfidf\n",
    "4. Opposition with Embeddings\n",
    "5. Both with Tfidf\n",
    "6. Both with Embeddings\n",
    "\n",
    "\n",
    "The variables to pay attention too are `feature` and `key`\n",
    "\n",
    "`key` can be support , oppostion or both\n",
    "`feature` can be tfidf or embedding\n",
    "\n",
    "\n",
    "if  `key` is both then set  `both` in  `Data(testset[testset['data_type'] == 'train'], feature=feature ,both=?)` to `True`\n",
    "\n",
    "e.g Data(testset[testset['data_type'] == 'train'], feature=feature ,both=True)\n",
    "\n",
    "Else if `key` is not both, thus `support` or `opposition` then set `both` to `False`\n",
    "\n",
    "Data(testset[testset['data_type'] == 'train'], feature=feature ,both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Set, Dict, Tuple\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (\n",
    "    Sequential as Seq,\n",
    "    Linear as Lin,\n",
    "    ReLU,\n",
    "    BatchNorm1d,\n",
    "    AvgPool1d,\n",
    "    Sigmoid,\n",
    "    Conv1d,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "from deepsetmodel import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvc-test\n",
    "\n",
    "\n",
    "trec-2015\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Here i load a paired datatset.\n",
    "\n",
    "Unlike the other (unpaird) datatset which contains individual briefs. \n",
    "\n",
    "Each row of the paired datast contains two set of briefs. Where each set corresponds to either oppostion and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132, 8), (543, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICENUMBER = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(F\"cuda:{DEVICENUMBER}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "PAIRED_PATH = '../dataset/paired_testset.csv' #'../summaries/summarized_paired_testset.csv' # '../dataset/paired_testset.csv'\n",
    "\n",
    "testset = pd.read_csv(PAIRED_PATH, sep=',',index_col=0)\n",
    "\n",
    "testset = testset.loc[testset['data_type'] == 'train']\n",
    "\n",
    "# randomly set 20% of the data to test\n",
    "testset['data_type'] = testset['data_type'].apply(lambda x: \"test\" if random.random() < 0.2 else \"train\")\n",
    "testset[testset['data_type'] == 'test'].shape , testset[testset['data_type'] == 'train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader *\n",
    "\n",
    "Just like the LLM Notebook you will have to run the cells below multiple times to run different experiments.\n",
    "\n",
    "As of the time this note was written,  If you want to specify the input type (\"tfidf\" or \"embedding\"), then set feature variable below.\n",
    "\n",
    "The Data class returns a pytorch dataset object.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data class definition\n",
    "\n",
    "Below is the signature of the Data class:\n",
    "\n",
    "<font color=\"blue\">def __init__(self,df,feature = 'tfidf', getEmbeddings = sentence_model.encode ,support_pipe = '../pipes/support-tfidf.joblib', opposition_pipe = '../pipes/oppose-tfidf.joblib', both =False, both_pipe = '../pipes/both-tfidf.joblib')</font>\n",
    "\n",
    "`self.feature`: This specifies the feature engineering technique to use on the dataset. \n",
    "                There are only 2 feature types implemented: [\"tfidf\", \"embeddings\"]\n",
    "\n",
    "\n",
    "`self.getEmbeddings`: This refers to the embedding function that will be used on the text. You can pick use your own embedding function. You don't have to specify an embedding function the default is already specified for you. \n",
    "\n",
    "`self.both`: When set to True a dataset where the supporting and opposing briefs are joined (Unioned) together to from one set of briefs.\n",
    "             When Set to False a dataset of disjointed supporting and oppossing breifs are joined. \n",
    "             You have to make sure that if you set this to true, then you have to set the configuration for the model to accept datasets that are joined.\n",
    "\n",
    "`self.support_pipe, self.opposition_pipe`: These are paths to pipes that convert text to tfidf vectors. Default paths are provided, so you don't have to explicitly set it.\n",
    "\n",
    "`self.both_pipe`: This is a path that converst text to tfidf vectors. This requires particular attention, because this pipe is constructed from both support and opposition. It is does a requirement is you set `self.both` to True. Default paths are provided, so you don't have to explicitly set it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples and Usecase:\n",
    "\n",
    "Example 1.\n",
    "<font color=\"blue\">train_data = Data(testset[testset['data_type'] == 'train'], feature='embedding' ,both=True)</font>:\n",
    "\n",
    "returns an embedding dataset where support and oppositions are combined.\n",
    "\n",
    "Example 2.\n",
    "<font color=\"blue\"> train_data = Data(testset[testset['data_type'] == 'test'], feature='tfidf' ,both=False) </font>:\n",
    "\n",
    "returns a tfidf dataset where where support and opposiontions are seperated.\n",
    "\n",
    "Example 3.\n",
    "```\n",
    "def embedding_func(brief):\n",
    "    \n",
    "    ....\n",
    "```\n",
    "<font color=\"blue\"> train_data = Data(testset[testset['data_type'] == 'test'], feature='embedding',both=False , getEmbeddings = embedding_func ): </font>\n",
    "\n",
    "returns a embedding dataset where the embedding function is explicitly defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self,df,feature = 'tfidf', getEmbeddings = sentence_model.encode ,support_pipe = '../pipes/support-tfidf.joblib', opposition_pipe = '../pipes/oppose-tfidf.joblib', both =False, both_pipe = '../pipes/both-tfidf.joblib'):\n",
    "        self.df = df    \n",
    "        supports = self.df['support'].values\n",
    "        oppositions = self.df['opposition'].values\n",
    "        self.folder_id = self.df['folder_id'].values\n",
    "        self.y = self.df['outcome'].values \n",
    "        # convert list of stings to list of lists of stings\n",
    "        supports = list(map(lambda x: ast.literal_eval(x), supports))\n",
    "        oppositions = list(map(lambda x: ast.literal_eval(x), oppositions))\n",
    "        self.both = both\n",
    "        if self.both:\n",
    "            self.combined = list(map(lambda x,y: x+y, supports,oppositions))\n",
    "\n",
    "        self.getEmbeddings = getEmbeddings\n",
    "        \n",
    "        if self.both == False:\n",
    "            self.max_len_brief = max(self.findMaxLen(supports),self.findMaxLen(oppositions))\n",
    "        else:\n",
    "            self.max_len_brief = self.findMaxLen(self.combined)\n",
    "\n",
    "        if feature == 'tfidf':\n",
    "            if self.both == False:\n",
    "                support_pipe = load(support_pipe)\n",
    "                opposition_pipe = load(opposition_pipe)\n",
    "                getSupport = lambda x: self.stringsToTfidfs(x,support_pipe)\n",
    "                getOpposition = lambda x: self.stringsToTfidfs(x,opposition_pipe)\n",
    "\n",
    "\n",
    "                self.supports = list(map( getSupport, supports))\n",
    "                self.oppositions = list(map( getOpposition, oppositions))\n",
    "\n",
    "            else:\n",
    "                both_pipe = load(both_pipe)\n",
    "                getTfidf= lambda x: self.stringsToTfidfs(x,both_pipe)\n",
    "                self.combined = list(map( getTfidf, self.combined))\n",
    "\n",
    "        elif feature == 'embedding':\n",
    "            if self.both == False:\n",
    "                self.supports: list = list(map(lambda x: self.stringsToEmbeddings(x), supports))\n",
    "                self.oppositions: list = list(map(lambda x: self.stringsToEmbeddings(x), oppositions))\n",
    "            else:\n",
    "                self.combined: list = list(map(lambda x: self.stringsToEmbeddings(x), self.combined))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.both == False:\n",
    "            return len(self.supports)\n",
    "        else:\n",
    "            return len(self.combined)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = 1.0 if self.y[idx] == 'grant' else 0.0\n",
    "\n",
    "        if hasattr(self, 'combined') and self.both == True:\n",
    "            return self.combined[idx] , y , self.folder_id[idx]\n",
    "        else:\n",
    "            return self.supports[idx] , self.oppositions[idx] , y , self.folder_id[idx]\n",
    "        \n",
    "    def findMaxLen(self,x):\n",
    "        max_len = 0\n",
    "        for i in range(len(x)):\n",
    "            row = x[i]\n",
    "            if len(row) > max_len:\n",
    "                max_len = len(row)\n",
    "        return max_len\n",
    "\n",
    "    def stringsToTfidfs(self,briefs: List[str],pipe):\n",
    "        tfidfs = torch.tensor(pipe.transform(briefs).toarray(),dtype=torch.float32)\n",
    "\n",
    "        return self.padFeatures(tfidfs)\n",
    "    \n",
    "\n",
    "    \n",
    "    def stringsToEmbeddings(self,briefs: List[str]):\n",
    "        embeddings =  torch.tensor(self.getEmbeddings(briefs),dtype=torch.float32)\n",
    "        return self.padFeatures(embeddings)\n",
    "    \n",
    "    def padFeatures(self,features: List[torch.tensor]):\n",
    "        num_padding = self.max_len_brief - features.shape[0]\n",
    "        padding = nn.ConstantPad2d((0, 0, 0, num_padding), 0)\n",
    "        features = padding(features)\n",
    "        features = features.T\n",
    "        return features\n",
    "    \n",
    "\n",
    "feature = 'tfidf' # 'tfidf' or embedding\n",
    "\n",
    "train_data = Data(testset[testset['data_type'] == 'train'], feature=feature ,both=True)\n",
    "test_data = Data(testset[testset['data_type'] == 'test'], feature=feature ,both=True)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# warning about pickle version *Vectorizer from version 1.3.2 when using version 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.max_len_brief, test_data.max_len_brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[testset['data_type'] == 'test']['opposition'].apply(lambda x: len(ast.literal_eval(x))).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation *\n",
    "\n",
    "In the cell below is where the size of the model is defined.\n",
    "Here you have to ability to increase or decreace the number of hidden units per layer.\n",
    "\n",
    "Just like the Dataloader tab above you have to run this cell once per experiment.\n",
    "\n",
    "You can only select one out of three types of models [\"support\", \"opposition\",\"both\"]\n",
    "\n",
    "specify your choice in the variable key\n",
    "\n",
    "Example\n",
    "``` key = \"both\" ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Notes to myself:\n",
    "\n",
    "The performance of the DeepSet model maybe hampered because of the small latent space.\n",
    "The machie i am using cannot handle a larger latent space. Once you get a larger GPU memory retry this scipt with a larger latent space\n",
    "\n",
    "\n",
    "\n",
    "Ideas on reducing the load on GPUs:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html\n",
    "\n",
    "When you have time learn this:\n",
    "\n",
    "https://docs.wandb.ai/guides/model_registry/walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TFIDF is quiet big so i may have to reduce the hiden layers width\n",
    "# the latent space has the be atleast the size of the input\n",
    "\n",
    "models = {}\n",
    "optimizers = {}\n",
    "\n",
    "key = \"both\"\n",
    "\n",
    "if key == \"support\":\n",
    "    input_size = train_data.supports[0].shape[0]\n",
    "elif key == \"opposition\":\n",
    "    input_size = train_data.oppositions[0].shape[0]\n",
    "else: #key == \"both\"    \n",
    "    input_size = train_data.combined[0].shape[0]\n",
    "\n",
    "\n",
    "max_len_brief = train_data.max_len_brief\n",
    "\n",
    "hidden1 = int(input_size /5)\n",
    "hidden2 = int(hidden1 / 4)\n",
    "hidden3 = int(hidden2 / 3)\n",
    "classify1 = int(hidden3 /2)\n",
    "\n",
    "models[key] = DeepSets(input_size, max_len_brief , hidden1, hidden2, hidden3, classify1).to(device)\n",
    "\n",
    "latent_size = int(input_size / 10)\n",
    "hidden_size = latent_size\n",
    "output_size =  1\n",
    "\n",
    "\n",
    "## what does Bachnorm and conv1d work?\n",
    "lr = 1e-4   \n",
    "optimizers[key] = torch.optim.Adam(models[key].parameters(), lr=lr)\n",
    "#optimizers[\"opposition\"] = torch.optim.Adam(models[\"opposition\"].parameters(), lr=1e-4)\n",
    "#optimizers[\"both\"] = torch.optim.Adam(models[\"both\"].parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "These are functions for  training, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, total, batch_size, leave=False , datatype='support', loss_fn= nn.BCELoss()):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "\n",
    "    t = tqdm(enumerate(loader), total=total /batch_size, leave=leave)\n",
    "\n",
    "    csv = {'folder':[],'prediction':[], 'score':[], 'truth':[]}\n",
    "\n",
    "    for i, data in t:\n",
    "\n",
    "        if datatype != \"both\":\n",
    "            supports, oppositions, y , folder_id = data\n",
    "            supports = supports.to(device)\n",
    "            oppositions = oppositions.to(device)\n",
    "        else:\n",
    "            combined, y , folder_id = data\n",
    "            combined = combined.to(device)\n",
    "\n",
    "        y = y.float()\n",
    "        y = y.reshape(-1,1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if datatype == 'support':\n",
    "            outputs= model(supports)\n",
    "        elif datatype == 'opposition':\n",
    "            outputs= model(oppositions)\n",
    "        elif datatype == 'both':\n",
    "            outputs= model(combined)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "        predictions = (outputs > 0.5)\n",
    "        acc = (predictions == y).sum().item()\n",
    "        sum_acc += acc\n",
    "        avg_acc =  acc /batch_size\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        t.set_description(f\"batch_loss_{datatype}: {loss.item():.4f} \\t| sum_loss_{datatype}: {sum_loss:.4f}\\n batch_accuracy_{datatype}: {avg_acc:.4f}\")\n",
    "        \n",
    "        t.refresh()\n",
    "\n",
    "        csv['folder'].extend(folder_id)\n",
    "        csv['prediction'].extend(predictions.cpu().numpy().flatten())\n",
    "        csv['score'].extend(outputs.cpu().numpy().flatten())\n",
    "        csv['truth'].extend(y.cpu().numpy().flatten())\n",
    "\n",
    "        \n",
    "    # what is the (i+1) for?\n",
    "        \n",
    "    return sum_loss  / len(loader.dataset) , sum_acc / len(loader.dataset) , pd.DataFrame(csv)\n",
    "\n",
    "\n",
    "def train(model, optimizer, loader, total, batch_size, leave=False, datatype='support', loss_fn= nn.BCELoss()):\n",
    "    model.train()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    t = tqdm(enumerate(loader), total=total /batch_size, leave=leave)\n",
    "    for i, data in t:\n",
    "\n",
    "        if key != \"both\":\n",
    "                \n",
    "            supports, oppositions, y , _ = data\n",
    "            supports = supports.to(device)\n",
    "            oppositions = oppositions.to(device)\n",
    "\n",
    "        else:\n",
    "            combined, y , _ = data\n",
    "            combined = combined.to(device)\n",
    "\n",
    "        y = y.float()\n",
    "        y = y.reshape(-1,1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if datatype == 'support':\n",
    "            outputs= model(supports)\n",
    "        elif datatype == 'opposition':\n",
    "            outputs= model(oppositions)\n",
    "        elif datatype == 'both':\n",
    "            outputs= model(combined)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        #wandb.log({\"batch_loss\": loss.item() } )\n",
    "      \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        t.set_description(f\"batch_loss_{datatype}: {loss.item():.4f} \\t| sum_loss_{datatype}: {sum_loss:.4f}\")\n",
    "        t.refresh()\n",
    "\n",
    "    return sum_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "The cell below is where the model is trained , tested, used for inference and saved to disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303530556d11427c8a96ea31fee4c19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moqcardoso\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratchB/oqcardoso/gvc-testfinal/unsummarized/permotion/wandb/run-20240429_180913-79p1a3tm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oqcardoso/DeepSets/runs/79p1a3tm' target=\"_blank\">boths-tfidf-epochs:300-patience:100 epochs</a></strong> to <a href='https://wandb.ai/oqcardoso/DeepSets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oqcardoso/DeepSets' target=\"_blank\">https://wandb.ai/oqcardoso/DeepSets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oqcardoso/DeepSets/runs/79p1a3tm' target=\"_blank\">https://wandb.ai/oqcardoso/DeepSets/runs/79p1a3tm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aff021b39cb40a98e904574a9c05523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32b682cc1054a77a3810dea1a889b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Training Loss:   0.3555\n",
      "           Validation Loss: 0.4364\n",
      "           Validation Accuracy: 0.5000\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd289b84a2464732ae23dc14bfb14ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de7166a12144ccd9da64a22a4dac8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Training Loss:   0.3184\n",
      "           Validation Loss: 0.4302\n",
      "           Validation Accuracy: 0.5000\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71110c8a602e4369a4e67c4bd9685dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ad7342c0d3431d8b5ca59770680556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Training Loss:   0.3077\n",
      "           Validation Loss: 0.4148\n",
      "           Validation Accuracy: 0.5205\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e5a92aaaae4f9bbc7a12d8ae4fb04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d1b367e884bd1bd4e987841ee4504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Training Loss:   0.2696\n",
      "           Validation Loss: 0.3792\n",
      "           Validation Accuracy: 0.5616\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237b00a9db9d464f8efd78d4f630ad2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc935b98fb774540b5ab05466e768423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Training Loss:   0.2911\n",
      "           Validation Loss: 0.3592\n",
      "           Validation Accuracy: 0.5548\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813262777bb845f1a62c98a0c88d1053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5c0e263ee8419781c81e23944544ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Training Loss:   0.2705\n",
      "           Validation Loss: 0.4125\n",
      "           Validation Accuracy: 0.5685\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa09d4b49d143e28dfff005a8101d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b189d5a12764e9eaf09d9357146272c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Training Loss:   0.2664\n",
      "           Validation Loss: 0.3661\n",
      "           Validation Accuracy: 0.5822\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bae309984544a5a640b10ba1ee794f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ca6eb81c89436ab6f60ed350bce52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Training Loss:   0.2556\n",
      "           Validation Loss: 0.4212\n",
      "           Validation Accuracy: 0.5890\n",
      "New best model saved to: ../models/DeepSets_both_tfidf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996fcebfaf104631a02ab07ace4a586b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b3d693bca044f68d65af21b263b969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Training Loss:   0.2622\n",
      "           Validation Loss: 0.4479\n",
      "           Validation Accuracy: 0.5479\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecd68bc93424e75902cfccecea6da6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef7b7bf95bf461c96b802365a8b1048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Training Loss:   0.2604\n",
      "           Validation Loss: 0.4429\n",
      "           Validation Accuracy: 0.5342\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7282beb48dc4b5c8fc562921c519016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e21f7c81964fa2a59171e1e532feb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss:   0.2524\n",
      "           Validation Loss: 0.4494\n",
      "           Validation Accuracy: 0.5685\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663788eaaa9c4783a857e9842eb46d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7640903421e44a34bf401fb091ec98f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss:   0.2600\n",
      "           Validation Loss: 0.5172\n",
      "           Validation Accuracy: 0.5890\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926e69415e8f4c87a1288afeea760198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae154d244f3d49f689da9d5795470988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "n_epochs = 300\n",
    "stale_epochs = 0\n",
    "best_valid_acc = 0.0\n",
    "patience = 100\n",
    "t = tqdm(range(0, n_epochs))\n",
    "  \n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DeepSets\",  \n",
    "    name= f\"{key}s-{feature}-epochs:{n_epochs}-patience:{patience} epochs\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \n",
    "    \"lr\": lr,\n",
    "\n",
    "    \"dataset\": f\"single-{key}\",\n",
    "\n",
    "    \"epochs\": n_epochs,\n",
    "\n",
    "    \"patience\": patience,\n",
    "\n",
    "    \"architecture\":\"ConvolutionalDeepSets\",\n",
    "\n",
    "    \"hidden1\" : hidden1,\n",
    "\n",
    "    \"hidden2\" : hidden2,\n",
    "\n",
    "    \"hidden3\" : hidden3,\n",
    "\n",
    "    \"classify1\" : classify1,\n",
    "\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in t:\n",
    "    avg_loss = train(\n",
    "        model=models[key], \n",
    "        optimizer=optimizers[key], \n",
    "        loader=train_loader, \n",
    "        total=len(train_data), \n",
    "        batch_size=batch_size, \n",
    "        leave=bool(epoch == n_epochs - 1),\n",
    "        datatype=key \n",
    "    )\n",
    "    \n",
    "    \n",
    "    valid_loss, valid_acc , csv = test(\n",
    "        model=models[key],\n",
    "        loader=test_loader, \n",
    "        total=len(test_data), \n",
    "        batch_size=batch_size, \n",
    "        leave=bool(epoch == n_epochs - 1),\n",
    "        datatype=key\n",
    "    )\n",
    "    \n",
    "    wandb.log({\"train_loss\": avg_loss, \"valid_loss\": valid_loss, \"valid_acc\": valid_acc})\n",
    "\n",
    "    print(\"Epoch: {:02d}, Training Loss:   {:.4f}\".format(epoch, avg_loss))\n",
    "    print(\"           Validation Loss: {:.4f}\".format(valid_loss))\n",
    "    print(\"           Validation Accuracy: {:.4f}\".format(valid_acc))\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        modpath = osp.join(f\"../models/DeepSets_{key}_{feature}.pth\")\n",
    "        print(\"New best model saved to:\", modpath)\n",
    "        torch.save(models[key].state_dict(), modpath)\n",
    "        # save csv\n",
    "        csv[\"folder\"] = csv[\"folder\"].astype(int)\n",
    "        csv[\"prediction\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"prediction\"]]\n",
    "        csv[\"truth\"] = [\"grant\" if x == 1 else \"deny\" for x in csv[\"truth\"]]\n",
    "        \n",
    "        csv.to_csv(f\"../predictions/DeepSets_{key}_{feature}_predictions.csv\", index=False)\n",
    "\n",
    "        stale_epochs = 0\n",
    "    else:\n",
    "        print(\"Stale epoch\")\n",
    "        stale_epochs += 1\n",
    "    if stale_epochs >= patience:\n",
    "        print(\"Early stopping after %i stale epochs\" % patience)\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "del models[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 49390, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
